---
title: "EyeSpeak Sinhala – Eye Controlled Sinhala Keyboard (Ongoing Research)"

summary: "Research and development of an eye-controlled Sinhala virtual keyboard using gaze interaction, dwell-free mechanisms, and optimized vowel and diacritic prediction to improve accessibility and text-entry efficiency."
images:
  - "/images/projects/eyespeak/cover-01.png"
  - "/images/projects/eyespeak/cover-02.png"
team:
  - name: "Nirmani Umasha"
    role: "Researcher & Software Developer"
    avatar: "/images/avatar.jpg"
    linkedIn: "http://www.linkedin.com/in/nirmani-umasha-49634a285"
link: "https://github.com/sachininirmani/EyespeakSinhala"
---

## Overview

EyeSpeak Sinhala is an ongoing research project focused on developing an eye-controlled virtual keyboard for the Sinhala language. The system uses eye-tracking technology to enable hands-free text entry, aiming to improve accessibility for users with motor impairments while maintaining efficiency, accuracy, and usability.

## Key Features

- **Eye-Controlled Text Entry**: Implemented gaze-based interaction using a Tobii eye tracker, allowing users to select characters and words without physical input devices.
- **Dwell-Free and Hybrid Interaction**: Designed interaction mechanisms that reduce reliance on fixed dwell times, minimizing eye fatigue and improving typing speed.
- **Optimized Sinhala Keyboard Layout**: Developed and evaluated multiple keyboard layouts optimized for Sinhala’s large character set, including consonants, vowels, and diacritics.
- **Multi-Stage Vowel & Diacritic Prediction**: Introduced intelligent vowel and diacritic prediction mechanisms to reduce keystrokes and improve text-entry efficiency.
- **Real-Time Gaze Processing**: Integrated real-time gaze data processing for responsive and accurate selection feedback.
- **Evaluation Framework**: Built an evaluation runner to collect performance metrics such as typing speed, accuracy, keystrokes per character, and user feedback.

## Technologies Used

- **React & TypeScript**: For building the interactive frontend keyboard interface.
- **Python**: For gaze data processing, evaluation logic, and experimental tooling.
- **Tobii Eye Tracker**: For capturing real-time eye-gaze input.
- **Human–Computer Interaction (HCI) Methods**: For layout optimization, usability evaluation, and performance analysis.

## Challenges and Learnings

A major challenge was designing an efficient interaction model for Sinhala, which has a large and complex character set compared to Latin-based languages. Balancing speed, accuracy, and eye fatigue required multiple iterations of keyboard layouts and interaction techniques. This project deepened my understanding of gaze-based interaction design, accessibility-focused HCI principles, and data-driven evaluation of user interfaces.

## Outcome

EyeSpeak Sinhala is an ongoing research project with promising results in improving accessibility and text-entry performance for Sinhala users. The work contributes toward assistive technology research and lays the foundation for further studies in eye-based interaction, adaptive keyboard layouts, and predictive text systems for low-resource languages.
